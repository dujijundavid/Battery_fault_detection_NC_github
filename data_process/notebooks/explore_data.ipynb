{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Battery Data Exploration\n",
                "\n",
                "This notebook helps you explore and inspect battery charging data.\n",
                "\n",
                "**Use this notebook instead of creating separate Python scripts for data exploration.**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql import SparkSession\n",
                "import yaml\n",
                "\n",
                "# Initialize Spark\n",
                "spark = SparkSession.builder \\\n",
                "    .appName(\"DataExploration\") \\\n",
                "    .getOrCreate()\n",
                "\n",
                "print(\"✓ Spark session initialized\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load config to get data paths\n",
                "with open('../config.yaml', 'r') as f:\n",
                "    config = yaml.safe_load(f)\n",
                "\n",
                "input_path = config['data']['input']\n",
                "output_path = config['data']['output']\n",
                "\n",
                "print(f\"Input:  {input_path}\")\n",
                "print(f\"Output: {output_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Explore Raw Parquet Files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read a sample parquet file\n",
                "# Replace with actual path to a specific parquet file\n",
                "sample_path = f\"{input_path}/car_example/file.parquet\"\n",
                "\n",
                "try:\n",
                "    df_raw = spark.read.parquet(sample_path)\n",
                "    print(\"✓ Parquet file loaded successfully\\n\")\n",
                "    \n",
                "    # Show schema\n",
                "    print(\"Schema:\")\n",
                "    df_raw.printSchema()\n",
                "    \n",
                "    # Show sample data\n",
                "    print(\"\\nSample data (first 5 rows):\")\n",
                "    df_raw.show(5)\n",
                "    \n",
                "    # Count rows\n",
                "    print(f\"\\nTotal rows: {df_raw.count():,}\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"Error: {e}\")\n",
                "    print(\"\\nTip: Update 'sample_path' with an actual parquet file path\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Check Column Names"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List all columns\n",
                "print(\"Available columns:\")\n",
                "for i, col in enumerate(df_raw.columns, 1):\n",
                "    print(f\"{i:2d}. {col}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Basic Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get summary statistics for numerical columns\n",
                "df_raw.select([\n",
                "    'bms_total_voltage',\n",
                "    'bms_total_current',\n",
                "    'bms_soc',\n",
                "    'bms_temp_max_value',\n",
                "    'odo'\n",
                "]).describe().show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Explore Processed Output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read processed Delta Lake output\n",
                "try:\n",
                "    df_output = spark.read.format(\"delta\").load(output_path)\n",
                "    print(\"✓ Processed data loaded successfully\\n\")\n",
                "    \n",
                "    # Show schema\n",
                "    print(\"Schema:\")\n",
                "    df_output.printSchema()\n",
                "    \n",
                "    # Show sample\n",
                "    print(\"\\nSample windows:\")\n",
                "    df_output.show(5, truncate=False)\n",
                "    \n",
                "    # Statistics\n",
                "    total_windows = df_output.count()\n",
                "    total_cars = df_output.select(\"car_name\").distinct().count()\n",
                "    \n",
                "    print(f\"\\nTotal vehicles: {total_cars}\")\n",
                "    print(f\"Total windows: {total_windows:,}\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"Error: {e}\")\n",
                "    print(\"\\nTip: Run data_process.py first to generate output data\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Windows per Vehicle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Count windows per vehicle\n",
                "try:\n",
                "    df_output.groupBy(\"car_name\") \\\n",
                "        .count() \\\n",
                "        .orderBy(\"count\", ascending=False) \\\n",
                "        .show(20, truncate=False)\n",
                "except:\n",
                "    print(\"Run previous cell first to load output data\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Inspect Window Data Structure"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get one window sample\n",
                "try:\n",
                "    sample_window = df_output.first()\n",
                "    \n",
                "    print(\"Sample window metadata:\")\n",
                "    print(f\"  Car: {sample_window['car_name']}\")\n",
                "    print(f\"  Charge session: {sample_window['charge_number']}\")\n",
                "    print(f\"  Window ID: {sample_window['window_id']}\")\n",
                "    print(f\"  Label: {sample_window['label']}\")\n",
                "    print(f\"  SOC range: {sample_window['soc_range']}\")\n",
                "    print(f\"  Voltage range: {sample_window['volt_range']}\")\n",
                "    \n",
                "    print(f\"\\nWindow data (time series):\")\n",
                "    print(f\"  Length: {len(sample_window['window_data'])} timesteps\")\n",
                "    print(f\"  Features per timestep: {len(sample_window['window_data'][0])}\")\n",
                "    print(f\"\\n  First 3 timesteps:\")\n",
                "    for i, timestep in enumerate(sample_window['window_data'][:3]):\n",
                "        print(f\"    {i}: {timestep}\")\n",
                "        \n",
                "except:\n",
                "    print(\"Run cell 4 first to load output data\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Filter and Query Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Find windows for a specific car\n",
                "car_name = \"car_example\"  # Replace with actual car name\n",
                "\n",
                "try:\n",
                "    car_windows = df_output.filter(f\"car_name = '{car_name}'\")\n",
                "    print(f\"Windows for {car_name}: {car_windows.count()}\")\n",
                "    car_windows.show(10)\n",
                "except:\n",
                "    print(\"Update car_name and run cell 4 first\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Custom Analysis\n",
                "\n",
                "Add your own exploration code below:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your custom code here\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}